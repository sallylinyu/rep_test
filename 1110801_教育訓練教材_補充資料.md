## Streaming ETL and Analytics on Confluent with Maritime AIS Data

- https://www.confluent.io/blog/streaming-etl-and-analytics-for-real-time-location-tracking/
- https://gpsd.gitlab.io/gpsd/AIVDM.html#_ais_payload_interpretation
  - AIS Message types

## Gitpod

- https://gitpod.io/
- Create workspace
  - https://github.com/confluentinc/demo-scene

## Print topic content

- `ksql> PRINT ais LIMIT 5;`
- https://docs.ksqldb.io/en/latest/developer-guide/ksqldb-reference/print/

## Create stream from a topic

- `ksql> CREATE STREAM AIS_RAW (MSG VARCHAR) WITH (KAFKA_TOPIC='ais', FORMAT='KAFKA');`
- https://docs.ksqldb.io/en/latest/developer-guide/ksqldb-reference/create-stream/
- https://docs.ksqldb.io/en/latest/reference/serialization/#kafka

## Push a continuous stream of updates

- `ksql> SELECT * FROM AIS_RAW EMIT CHANGES LIMIT 5;`
- `ksql> SELECT EXTRACTJSONFIELD(msg,'$.type') AS MSG_TYPE FROM AIS_RAW EMIT CHANGES LIMIT 5;`
- https://docs.ksqldb.io/en/latest/developer-guide/ksqldb-reference/select-push-query/
  - Push Query
  - Transient Queries

## Push query with condition

```sql
SELECT TIMESTAMPTOSTRING(ROWTIME,'yyyy-MM-dd HH:mm:ss','Europe/London') AS TS,
       CAST(EXTRACTJSONFIELD(msg,'$.type') AS INT)                      AS MSG_TYPE,
       CAST(EXTRACTJSONFIELD(msg,'$.status_text') AS VARCHAR)           AS STATUS_TEXT
FROM   AIS_RAW
WHERE  EXTRACTJSONFIELD(msg,'$.type') = '1'
EMIT CHANGES;
```

## Create stream from persistent query (Ship position reports, type 1, 2, or 3 messages)

```sql
CREATE OR REPLACE STREAM AIS_MSG_TYPE_1_2_3 WITH (FORMAT='AVRO') AS 
SELECT
  CAST(EXTRACTJSONFIELD(msg,'$.class') AS VARCHAR) AS class,
  CAST(EXTRACTJSONFIELD(msg,'$.device') AS VARCHAR) AS device,
  CAST(EXTRACTJSONFIELD(msg,'$.type') AS INT) AS msg_type,
  CAST(EXTRACTJSONFIELD(msg,'$.repeat') AS INT) AS repeat,
  CAST(EXTRACTJSONFIELD(msg,'$.mmsi') AS VARCHAR) AS mmsi,
  CAST(EXTRACTJSONFIELD(msg,'$.scaled') AS BOOLEAN) AS scaled,
  CAST(EXTRACTJSONFIELD(msg,'$.status') AS INT) AS status,
  CAST(EXTRACTJSONFIELD(msg,'$.status_text') AS VARCHAR) AS status_text,
  CAST(EXTRACTJSONFIELD(msg,'$.turn') AS VARCHAR) AS turn,
  CAST(EXTRACTJSONFIELD(msg,'$.speed') AS DOUBLE) AS speed,
  CAST(EXTRACTJSONFIELD(msg,'$.accuracy') AS BOOLEAN) AS accuracy,
  CAST(EXTRACTJSONFIELD(msg,'$.lon') AS DOUBLE) AS lon,
  CAST(EXTRACTJSONFIELD(msg,'$.lat') AS DOUBLE) AS lat,
  CAST(EXTRACTJSONFIELD(msg,'$.course') AS DOUBLE) AS course,
  CAST(EXTRACTJSONFIELD(msg,'$.heading') AS INT) AS heading,
  CAST(EXTRACTJSONFIELD(msg,'$.second') AS INT) AS second,
  CAST(EXTRACTJSONFIELD(msg,'$.maneuver') AS INT) AS maneuver,
  CAST(EXTRACTJSONFIELD(msg,'$.raim') AS BOOLEAN) AS raim,
  CAST(EXTRACTJSONFIELD(msg,'$.radio') AS BIGINT) AS radio
FROM AIS_RAW
WHERE EXTRACTJSONFIELD(msg,'$.type') IN ('1' ,'2' ,'3' ,'18' ,'27')
   PARTITION BY CAST(EXTRACTJSONFIELD(msg,'$.mmsi') AS VARCHAR);
```

- https://github.com/confluentinc/demo-scene/blob/master/maritime-ais/ksql_statements.ksql#L8

## Create stream from persistent query (Ship and voyage data, type 5 messages)

``` sql
CREATE OR REPLACE STREAM AIS_MSG_TYPE_5 WITH (FORMAT='AVRO') AS 
SELECT
CAST(EXTRACTJSONFIELD(msg,'$.class') AS VARCHAR) AS class, 
CAST(EXTRACTJSONFIELD(msg,'$.device') AS VARCHAR) AS device, 
CAST(EXTRACTJSONFIELD(msg,'$.type') AS INT) AS msg_type, 
CAST(EXTRACTJSONFIELD(msg,'$.repeat') AS INT) AS repeat, 
CAST(EXTRACTJSONFIELD(msg,'$.mmsi') AS VARCHAR) AS mmsi, 
CAST(EXTRACTJSONFIELD(msg,'$.scaled') AS BOOLEAN) AS scaled, 
CAST(EXTRACTJSONFIELD(msg,'$.imo') AS BIGINT) AS imo, 
CAST(EXTRACTJSONFIELD(msg,'$.ais_version') AS INT) AS ais_version, 
CAST(EXTRACTJSONFIELD(msg,'$.callsign') AS VARCHAR) AS callsign, 
CAST(EXTRACTJSONFIELD(msg,'$.shipname') AS VARCHAR) AS shipname_raw, 
CONCAT(CAST(EXTRACTJSONFIELD(msg,'$.shipname') AS VARCHAR),' (',CAST(EXTRACTJSONFIELD(msg,'$.callsign') AS VARCHAR),')') AS shipname,
CAST(EXTRACTJSONFIELD(msg,'$.shiptype') AS INT) AS shiptype, 
CAST(EXTRACTJSONFIELD(msg,'$.shiptype_text') AS VARCHAR) AS shiptype_text, 
CAST(EXTRACTJSONFIELD(msg,'$.to_bow') AS INT) AS to_bow_m, 
CAST(EXTRACTJSONFIELD(msg,'$.to_stern') AS INT) AS to_stern_m, 
CAST(EXTRACTJSONFIELD(msg,'$.to_port') AS INT) AS to_port_m, 
CAST(EXTRACTJSONFIELD(msg,'$.to_starboard') AS INT) AS to_starboard_m, 
CAST(EXTRACTJSONFIELD(msg,'$.epfd') AS INT) AS epfd, 
CAST(EXTRACTJSONFIELD(msg,'$.epfd_text') AS VARCHAR) AS epfd_text, 
CAST(EXTRACTJSONFIELD(msg,'$.eta') AS VARCHAR) AS eta, 
CAST(EXTRACTJSONFIELD(msg,'$.draught') AS DOUBLE) AS draught, 
CAST(EXTRACTJSONFIELD(msg,'$.destination') AS VARCHAR) AS destination, 
CAST(EXTRACTJSONFIELD(msg,'$.dte') AS INT) AS dte
FROM AIS_RAW
WHERE EXTRACTJSONFIELD(msg,'$.type') = '5'
PARTITION BY CAST(EXTRACTJSONFIELD(msg,'$.mmsi') AS VARCHAR);
```

- https://github.com/confluentinc/demo-scene/blob/master/maritime-ais/ksql_statements.ksql#L81

## Query status report

```sql
SELECT MMSI, STATUS_TEXT, LON, LAT
FROM AIS_MSG_TYPE_1_2_3
WHERE MMSI = '257045940'
EMIT CHANGES;
```

## Query shipâ€™s characteristics

```sql
SELECT TIMESTAMPTOSTRING(ROWTIME,'HH:mm:ss','Europe/Oslo') AS TS,
       MMSI,
       SHIPNAME,
       DRAUGHT,
       DESTINATION
FROM AIS_MSG_TYPE_5
WHERE MMSI = '257045940'
EMIT CHANGES;
```

## Create a state table of ship information

```sql
CREATE TABLE SHIP_INFO AS
  SELECT A.MMSI,
         COUNT(*) AS EVENT_CT,
         MIN(ROWTIME)  AS FIRST_INFO_PING_TS,
         MAX(ROWTIME)  AS LAST_INFO_PING_TS,
         LATEST_BY_OFFSET(IMO) AS IMO,
         LATEST_BY_OFFSET(CALLSIGN) AS CALLSIGN,
         LATEST_BY_OFFSET(SHIPNAME_RAW) AS SHIPNAME_RAW,
         LATEST_BY_OFFSET(SHIPNAME) AS SHIPNAME,
         LATEST_BY_OFFSET(SHIPTYPE_TEXT) AS SHIPTYPE_TEXT,
         LATEST_BY_OFFSET(TO_BOW_M) AS TO_BOW_M,
         LATEST_BY_OFFSET(TO_STERN_M) AS TO_STERN_M,
         LATEST_BY_OFFSET(TO_PORT_M) AS TO_PORT_M,
         LATEST_BY_OFFSET(TO_STARBOARD_M) AS TO_STARBOARD_M,
        (LATEST_BY_OFFSET(TO_BOW_M) + LATEST_BY_OFFSET(TO_STERN_M)) * (LATEST_BY_OFFSET(TO_STARBOARD_M) + LATEST_BY_OFFSET(TO_PORT_M)) AS SHIP_AREA_M_SQ,
        (LATEST_BY_OFFSET(TO_BOW_M) + LATEST_BY_OFFSET(TO_STERN_M)) AS SHIP_LENGTH_M,
        (LATEST_BY_OFFSET(TO_STARBOARD_M) + LATEST_BY_OFFSET(TO_PORT_M)) AS SHIP_WIDTH_M,
         LATEST_BY_OFFSET(EPFD_TEXT) AS EPFD_TEXT,
         LATEST_BY_OFFSET(ETA) AS ETA,
         COLLECT_SET(ETA) AS ETA_LIST,
         LATEST_BY_OFFSET(DRAUGHT) AS DRAUGHT,
         LATEST_BY_OFFSET(DESTINATION) AS DESTINATION,
         COLLECT_SET(DESTINATION) AS DESTINATION_LIST
    FROM AIS_MSG_TYPE_5 A
    GROUP BY A.MMSI;
```

- https://github.com/confluentinc/demo-scene/blob/master/maritime-ais/ksql_statements.ksql#L199

## Query last ship info

```sql
SELECT MMSI,
       TIMESTAMPTOSTRING(LAST_INFO_PING_TS,'HH:mm:ss','Europe/London') AS LAST_INFO_PING_TS,
       SHIPNAME,
       DRAUGHT,
       DESTINATION
  FROM SHIP_INFO
  WHERE MMSI = '257045940';
```

## Join position reports with ship info to create

```sql
CREATE STREAM SHIP_STATUS_REPORTS WITH
  (KAFKA_TOPIC='SHIP_STATUS_REPORTS_V00') AS
SELECT STATUS_REPORT.ROWTIME AS STATUS_TS,
       STATUS_REPORT.*,
       SHIP_INFO.*,
       CASE
         WHEN STATUS_REPORT.LAT IS NULL OR STATUS_REPORT.LON IS NULL 
           THEN CAST(NULL AS STRUCT<`lat` DOUBLE, `lon` DOUBLE>)
         ELSE 
           STRUCT("lat" := STATUS_REPORT.LAT, "lon" := STATUS_REPORT.LON)
       END AS SHIP_LOCATION,
       1 AS DUMMY
FROM  AIS_MSG_TYPE_1_2_3 STATUS_REPORT
      LEFT JOIN SHIP_INFO SHIP_INFO
        ON STATUS_REPORT.MMSI = SHIP_INFO.MMSI
;
```

- https://github.com/confluentinc/demo-scene/blob/master/maritime-ais/ksql_statements.ksql#L233

## Given ship every movement along with information about itself

```sql
SELECT TIMESTAMPTOSTRING(STATUS_TS,'HH:mm:ss','Europe/Oslo') AS STATUS_TS,
             SHIP_LOCATION,
             STATUS_REPORT_STATUS_TEXT,
             SHIP_INFO_SHIPNAME,
             SHIP_INFO_DRAUGHT
        FROM SHIP_STATUS_REPORTS
       WHERE SHIP_INFO_MMSI = '257045940'
       EMIT CHANGES;
```

## Elasticsearch and Kibana

- Connector
  - Connection URLs
    - http://elasticsearch:9200

```json
PUT _index_template/rmoff_ais_01
{
  "index_patterns": [
    "ship_status_reports*"
  ],
  "template": {
    "mappings": {
      "dynamic_templates": [
        { "locations": { "match": "*_LOCATION", "mapping": { "type": "geo_point" } } },
        { "dates": { "match": "*_TS", "mapping": { "type": "date" } } }
      ]
    }
  }
}
GET ship_status_reports_v00/_mapping
```

## Kafka Connect

```sql
DROP CONNECTOR IF EXISTS SINK_ELASTIC_SHIP_STATUS_REPORTS_01;
CREATE SINK CONNECTOR SINK_ELASTIC_SHIP_STATUS_REPORTS_01 WITH (
  'connector.class'                     = 'io.confluent.connect.elasticsearch.ElasticsearchSinkConnector',
  'key.converter'                       = 'io.confluent.connect.avro.AvroConverter',
  'key.converter.schema.registry.url'   = 'http://schema-registry:8081',
  'value.converter'                     = 'io.confluent.connect.avro.AvroConverter',
  'value.converter.schema.registry.url' = 'http://schema-registry:8081',
  'connection.url'                      = 'http://elasticsearch:9200',
  'type.name'                           = '_doc',
  'topics.regex'                        = 'SHIP_STATUS_REPORTS_V.*',
  'key.ignore'                          = 'true',
  'schema.ignore'                       = 'false',
  'behavior.on.malformed.documents'     = 'ignore',
  'transforms'                          = 'topicname',
  'transforms.topicname.type'           = 'org.apache.kafka.connect.transforms.RegexRouter',
  'transforms.topicname.regex'          = '.*',
  'transforms.topicname.replacement'    = 'ship_status_reports'
);
```
